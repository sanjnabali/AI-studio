# MLOps Parameters for AI Studio
# Central configuration file for all machine learning pipeline parameters

# Experiment Configuration
experiment:
  name: "ai_studio_v1"
  version: "1.0.0"
  description: "Production-ready multimodal AI platform"
  author: "AI Studio Team"
  tags: ["multimodal", "small-models", "production"]

# Environment Configuration
environment:
  python_version: "3.9"
  cuda_version: "11.8"
  device: "auto"  # auto, cpu, cuda
  mixed_precision: true
  compile_models: false  # torch.compile for optimization

# Data Preparation Parameters
data_preparation:
  # Data sources
  sources:
    - "data/raw/code_conversations.jsonl"
    - "data/raw/creative_writing.jsonl"
    - "data/raw/analysis_tasks.jsonl"
    - "data/raw/summarization_pairs.jsonl"
    - "data/raw/multimodal_data.jsonl"
  
  # Processing settings
  max_sequence_length: 2048
  min_sequence_length: 10
  train_split: 0.8
  validation_split: 0.1
  test_split: 0.1
  random_seed: 42
  
  # Data quality filters
  filters:
    remove_duplicates: true
    min_quality_score: 0.7
    filter_languages: ["en"]
    remove_pii: true
    content_safety: true
  
  # Domain distribution
  domain_ratios:
    code: 0.3
    creative: 0.25
    analysis: 0.2
    summarization: 0.15
    multimodal: 0.1
  
  # Augmentation settings
  augmentation:
    enabled: true
    techniques:
      - "paraphrase"
      - "back_translate"
      - "synonym_replace"
    augmentation_ratio: 0.2

# Feature Extraction Parameters
feature_extraction:
  # Embedding models
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  embedding_dimension: 384
  batch_size: 64
  
  # Text processing
  tokenizer_settings:
    padding: "max_length"
    truncation: true
    return_attention_mask: true
  
  # Feature extraction options
  extract_linguistic_features: true
  extract_semantic_features: true
  extract_syntactic_features: false
  
  # Caching
  cache_embeddings: true
  cache_directory: "cache/embeddings/"

# Base Model Training Parameters
base_model_training:
  # Models to train
  models:
    phi2:
      model_name: "microsoft/phi-2"
      architecture: "transformer"
      context_length: 2048
      
    codet5:
      model_name: "Salesforce/codet5p-220m"
      architecture: "encoder-decoder"
      context_length: 512
      
    t5_small:
      model_name: "t5-small"
      architecture: "encoder-decoder"
      context_length: 512
  
  # Training hyperparameters
  training:
    learning_rate: 5e-5
    batch_size: 8
    gradient_accumulation_steps: 4
    num_epochs: 3
    warmup_steps: 500
    weight_decay: 0.01
    
    # Optimization
    optimizer: "adamw"
    lr_scheduler: "cosine"
    gradient_clipping: 1.0
    
    # Regularization
    dropout: 0.1
    attention_dropout: 0.1
    
  # Early stopping
  early_stopping:
    enabled: true
    patience: 3
    min_delta: 0.001
    monitor: "validation_loss"
  
  # Checkpointing
  checkpointing:
    save_steps: 1000
    save_total_limit: 3
    load_best_model_at_end: true

# Domain Fine-tuning Parameters
domain_finetuning:
  # Domain-specific configurations
  domains:
    code:
      base_model: "phi2"
      specialized_tasks: ["code_generation", "code_review", "debugging"]
      learning_rate: 3e-5
      epochs: 5
      
    creative:
      base_model: "phi2"
      specialized_tasks: ["story_writing", "poetry", "dialogue"]
      learning_rate: 4e-5
      epochs: 4
      
    analysis:
      base_model: "t5_small"
      specialized_tasks: ["data_analysis", "report_generation", "insights"]
      learning_rate: 3e-5
      epochs: 4
      
    summarization:
      base_model: "t5_small"
      specialized_tasks: ["text_summary", "document_analysis", "key_points"]
      learning_rate: 5e-5
      epochs: 3
  
  # Fine-tuning strategy
  strategy: "full_finetuning"  # full_finetuning, lora, prefix_tuning
  freeze_embeddings: false
  freeze_encoder: false
  
  # Task-specific loss weights
  loss_weights:
    generation: 1.0
    classification: 0.5
    similarity: 0.3

# LoRA Training Parameters
lora_training:
  # LoRA configuration
  lora_config:
    r: 16                    # Rank
    lora_alpha: 32          # Scaling parameter
    lora_dropout: 0.1       # Dropout rate
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
    bias: "none"            # none, all, lora_only
    task_type: "CAUSAL_LM"
  
  # Training parameters
  training:
    learning_rate: 2e-4
    batch_size: 16
    gradient_accumulation_steps: 2
    num_epochs: 10
    warmup_ratio: 0.1
    
  # Multiple adapters
  adapters:
    code_specialist:
      target_domains: ["code"]
      r: 16
      lora_alpha: 32
      
    creative_specialist:
      target_domains: ["creative"]
      r: 8
      lora_alpha: 16
      
    analysis_specialist:
      target_domains: ["analysis"]
      r: 12
      lora_alpha: 24
      
    summary_specialist:
      target_domains: ["summarization"]
      r: 8
      lora_alpha: 16

# Model Quantization Parameters
quantization:
  # Quantization methods
  methods:
    - "4bit"
    - "8bit"
  
  # 4-bit quantization (BitsAndBytes)
  bnb_4bit_config:
    load_in_4bit: true
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_compute_dtype: "float16"
  
  # 8-bit quantization
  bnb_8bit_config:
    load_in_8bit: true
    llm_int8_threshold: 6.0
    llm_int8_skip_modules: ["lm_head"]
  
  # Post-training quantization
  post_training_quantization:
    enabled: true
    calibration_dataset_size: 1000
    quantization_scheme: "dynamic"
  
  # Quality preservation
  quality_threshold: 0.95  # Minimum quality retention after quantization
  benchmark_tasks: ["code_generation", "text_completion", "summarization"]

# Evaluation Parameters
evaluation:
  # Evaluation datasets
  datasets:
    code_eval: "data/evaluation/code_tasks.jsonl"
    creative_eval: "data/evaluation/creative_tasks.jsonl"
    analysis_eval: "data/evaluation/analysis_tasks.jsonl"
    summary_eval: "data/evaluation/summary_tasks.jsonl"
    multimodal_eval: "data/evaluation/multimodal_tasks.jsonl"
  
  # Evaluation metrics
  metrics:
    automatic:
      - "bleu"
      - "rouge"
      - "bertscore"
      - "perplexity"
      - "exact_match"
    
    human_evaluation:
      - "quality"
      - "relevance"
      - "coherence"
      - "helpfulness"
  
  # Benchmark suites
  benchmarks:
    code:
      - "HumanEval"
      - "MBPP"
      - "CodeXGLUE"
    
    text:
      - "GLUE"
      - "SuperGLUE"
      - "HellaSwag"
    
    reasoning:
      - "GSM8K"
      - "MATH"
      - "StrategyQA"
  
  # Evaluation settings
  batch_size: 16
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  num_beams: 1
  
  # Statistical significance
  significance_tests: true
  confidence_level: 0.95
  num_bootstrap_samples: 1000

# RAG System Parameters
rag_training:
  # Document processing
  document_processing:
    chunk_size: 512
    chunk_overlap: 50
    chunking_strategy: "recursive"  # recursive, semantic, fixed
    
  # Embedding configuration
  embedding:
    model: "sentence-transformers/all-MiniLM-L6-v2"
    dimension: 384
    normalize_embeddings: true
    
  # Vector store configuration
  vector_store:
    type: "faiss"  # faiss, chroma, weaviate
    index_type: "flat"  # flat, hnsw, ivf
    distance_metric: "cosine"  # cosine, euclidean, dot_product
    
  # Retrieval settings
  retrieval:
    top_k: 5
    similarity_threshold: 0.7
    rerank_results: true
    rerank_model: "cross-encoder/ms-marco-MiniLM-L-2-v2"
    
  # Context enhancement
  context_enhancement:
    max_context_length: 1024
    context_overlap_handling: "truncate"  # truncate, summarize, merge
    add_metadata: true
    
  # Training data generation
  synthetic_qa_generation:
    enabled: true
    num_questions_per_chunk: 3
    question_types: ["factual", "inferential", "analytical"]

# Agent Training Parameters
agent_training:
  # Agent-specific configurations
  agents:
    code_agent:
      base_models: ["phi2", "codet5"]
      specialization_tasks:
        - "code_generation"
        - "code_review"
        - "bug_fixing"
        - "code_explanation"
        - "refactoring"
      
    text_agent:
      base_models: ["phi2", "t5_small"]
      specialization_tasks:
        - "creative_writing"
        - "text_completion"
        - "dialogue_generation"
        - "content_creation"
      
    rag_agent:
      base_models: ["phi2"]
      specialization_tasks:
        - "document_qa"
        - "information_retrieval"
        - "context_aware_generation"
      
    summarizer_agent:
      base_models: ["t5_small"]
      specialization_tasks:
        - "extractive_summarization"
        - "abstractive_summarization"
        - "multi_document_summary"
        - "key_insights_extraction"
      
    voice_agent:
      base_models: ["whisper", "speecht5"]
      specialization_tasks:
        - "speech_to_text"
        - "text_to_speech"
        - "voice_activity_detection"
        - "speaker_identification"
  
  # Multi-agent learning
  multi_agent_training:
    enabled: true
    collaboration_tasks: true
    cross_agent_knowledge_sharing: true
    
  # Reinforcement learning from human feedback (RLHF)
  rlhf:
    enabled: false  # Disabled for initial version
    reward_model_training: false
    ppo_training: false

# Model Validation Parameters
validation:
  # Validation criteria
  criteria:
    accuracy_threshold: 0.85
    latency_threshold_ms: 2000
    memory_limit_gb: 4
    throughput_min_rps: 10
    
  # Testing protocols
  testing:
    unit_tests: true
    integration_tests: true
    load_tests: true
    security_tests: true
    adversarial_tests: true
    
  # A/B testing
  ab_testing:
    enabled: true
    test_duration_days: 7
    statistical_power: 0.8
    minimum_effect_size: 0.05
    
  # Regression testing
  regression_testing:
    baseline_models: ["phi2_base", "t5_base"]
    performance_degradation_threshold: 0.05
    
  # Safety and ethics validation
  safety_validation:
    bias_detection: true
    toxicity_screening: true
    fairness_metrics: true
    content_safety: true

# Performance Benchmarking Parameters
benchmarking:
  # Hardware configurations to test
  hardware_configs:
    - name: "cpu_only"
      device: "cpu"
      memory_limit: "8GB"
      
    - name: "gpu_t4"
      device: "cuda"
      gpu_model: "Tesla T4"
      memory_limit: "16GB"
      
    - name: "gpu_v100"
      device: "cuda"
      gpu_model: "Tesla V100"
      memory_limit: "32GB"
  
  # Performance metrics
  metrics:
    - "inference_latency"
    - "throughput"
    - "memory_usage"
    - "gpu_utilization"
    - "energy_consumption"
    
  # Stress testing
  stress_testing:
    concurrent_requests: [1, 5, 10, 20, 50]
    request_patterns: ["constant", "burst", "ramp"]
    duration_minutes: 10
    
  # Optimization targets
  optimization_targets:
    latency_p95: 1500  # milliseconds
    throughput_min: 20  # requests per second
    memory_efficiency: 0.8  # utilization ratio
    
# Packaging Parameters
packaging:
  # Model packaging formats
  formats:
    - "huggingface"
    - "onnx"
    - "tensorrt"
    - "torchscript"
    
  # Container configuration
  containerization:
    base_image: "python:3.9-slim"
    include_dependencies: true
    optimize_size: true
    security_scanning: true
    
  # Model versioning
  versioning:
    scheme: "semantic"  # semantic, timestamp, hash
    auto_increment: true
    tag_strategy: "latest_stable"
    
  # Deployment artifacts
  artifacts:
    - "model_weights"
    - "tokenizer"
    - "configuration"
    - "inference_script"
    - "requirements.txt"
    - "dockerfile"
    - "health_check"

# Deployment Parameters
deployment:
  # Deployment environments
  environments:
    development:
      replicas: 1
      resources:
        cpu: "1"
        memory: "4Gi"
        gpu: "0"
        
    staging:
      replicas: 2
      resources:
        cpu: "2"
        memory: "8Gi"
        gpu: "0"
        
    production:
      replicas: 5
      resources:
        cpu: "4"
        memory: "16Gi"
        gpu: "1"
  
  # Auto-scaling configuration
  auto_scaling:
    enabled: true
    min_replicas: 2
    max_replicas: 20
    cpu_threshold: 70
    memory_threshold: 80
    
  # Health checks
  health_checks:
    liveness_probe:
      path: "/health"
      initial_delay: 30
      period: 10
      
    readiness_probe:
      path: "/ready"
      initial_delay: 5
      period: 5
      
  # Monitoring and logging
  monitoring:
    metrics_enabled: true
    logging_level: "INFO"
    distributed_tracing: true
    
  # Blue-green deployment
  blue_green:
    enabled: true
    switch_threshold: 0.95  # Success rate threshold for switching
    rollback_threshold: 0.90  # Threshold for automatic rollback
    
  # Canary deployment
  canary:
    enabled: true
    traffic_percentage: 10  # Initial canary traffic
    success_threshold: 0.95
    duration_minutes: 60

# Monitoring and Observability Parameters
monitoring:
  # Metrics collection
  metrics:
    business_metrics:
      - "request_count"
      - "response_time"
      - "error_rate"
      - "user_satisfaction"
      
    technical_metrics:
      - "cpu_usage"
      - "memory_usage"
      - "gpu_utilization"
      - "disk_io"
      - "network_io"
      
    ml_metrics:
      - "model_accuracy"
      - "prediction_confidence"
      - "data_drift"
      - "model_drift"
  
  # Alerting rules
  alerts:
    critical:
      - condition: "error_rate > 0.05"
        severity: "critical"
        
      - condition: "response_time > 5000"
        severity: "critical"
        
    warning:
      - condition: "cpu_usage > 0.8"
        severity: "warning"
        
      - condition: "memory_usage > 0.9"
        severity: "warning"
  
  # Data quality monitoring
  data_quality:
    schema_validation: true
    distribution_monitoring: true
    anomaly_detection: true
    drift_detection_window: "7d"
    
  # Model performance monitoring
  model_monitoring:
    performance_degradation_threshold: 0.1
    prediction_drift_threshold: 0.05
    feature_importance_tracking: true
    explainability_monitoring: true

# Security and Compliance Parameters
security:
  # Model security
  model_security:
    weight_encryption: true
    secure_inference: true
    adversarial_robustness: true
    
  # Data privacy
  data_privacy:
    pii_removal: true
    data_anonymization: true
    gdpr_compliance: true
    
  # API security
  api_security:
    authentication: true
    rate_limiting: true
    input_validation: true
    output_sanitization: true
    
  # Infrastructure security
  infrastructure_security:
    network_policies: true
    secrets_management: true
    vulnerability_scanning: true
    security_updates: "auto"

# Backup and Disaster Recovery
backup:
  # Backup schedule
  schedule:
    models: "daily"
    data: "hourly"
    configurations: "on_change"
    
  # Retention policy
  retention:
    daily_backups: 30
    weekly_backups: 12
    monthly_backups: 12
    
  # Disaster recovery
  disaster_recovery:
    rto: "4h"  # Recovery Time Objective
    rpo: "1h"  # Recovery Point Objective
    backup_locations: ["primary", "secondary", "cloud"]
    
  # Testing
  backup_testing:
    frequency: "monthly"
    automated_verification: true
    restore_testing: true